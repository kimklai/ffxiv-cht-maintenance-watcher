import requests
import re
import os
import time
from playwright.sync_api import sync_playwright

# --- é…ç½®å€ ---
webhook_raw = os.environ.get("DISCORD_WEBHOOK", "")
DISCORD_WEBHOOK_URLS = [url.strip() for url in webhook_raw.split(",") if url.strip()]
LAST_NEWS_FILE = "last_news_title.txt"

def send_to_discord(title, link, text_content):
    """ç™¼é€åˆ°æ‰€æœ‰è¨­å®šçš„ Discord Webhooks"""
    if len(text_content) > 3000:
        text_content = text_content[:3000] + "\n\n...(å…§å®¹éé•·)"

    payload = {
        "username": "FFXIV å…‰ä¹‹å·¥å…·äºº",
        "embeds": [{
            "title": title,
            "url": link,
            "description": text_content,
            "color": 3447003,
        }]
    }

    # éæ­·æ‰€æœ‰ç¶²å€ç™¼é€
    for url in DISCORD_WEBHOOK_URLS:
        try:
            res = requests.post(url, json=payload)
            if res.status_code in [200, 204]:
                print(f"âœ… æˆåŠŸç™¼é€åˆ° Webhook: {url[:30]}...")
            else:
                print(f"âŒ ç™¼é€å¤±æ•— ({res.status_code}): {url[:30]}...")
        except Exception as e:
            print(f"ç™¼é€è‡³ {url[:30]} æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")

def run_scraper():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        # 1. åˆ—è¡¨é æŠ“é€£çµ
        try:
            page.goto("https://www.ffxiv.com.tw/web/news/news_list.aspx?category=3", timeout=60000)
            page.wait_for_selector(".news_list .item")

            first_item = page.query_selector(".news_list .item")
            title = first_item.query_selector(".title a").inner_text().strip()
            link = "https://www.ffxiv.com.tw" + first_item.query_selector(".title a").get_attribute("href")

            # æª¢æŸ¥æ˜¯å¦å·²ç™¼é€é
            if os.path.exists(LAST_NEWS_FILE):
                with open(LAST_NEWS_FILE, "r", encoding="utf-8") as f:
                    if f.read().strip() == title:
                        print(f"ğŸ˜´ å·²è™•ç†éæœ€æ–°å…¬å‘Š: {title}")
                        return

            # 2. é€²å…¥å…§æ–‡é æŠ“å– .article
            page.goto(link, timeout=60000)
            page.wait_for_selector(".article")

            # ä½¿ç”¨ inner_text() å¯ä»¥ä¿ç•™å¤§éƒ¨åˆ†çš„æ›è¡Œèˆ‡ç¸®æ’æ’ç‰ˆ
            article_element = page.query_selector(".article")
            raw_text = article_element.inner_text().strip()

            # ç°¡å–®æ¸…ç†ï¼šå°‡ä¸‰å€‹ä»¥ä¸Šçš„é€£çºŒæ›è¡Œç¸®æ¸›ç‚ºå…©å€‹ï¼Œä¿æŒæ®µè½æ„Ÿä½†ä¸æµªè²»ç©ºé–“
            formatted_text = re.sub(r'\n{3,}', '\n\n', raw_text)

            # 3. åŸ·è¡Œç™¼é€
            send_to_discord(title, link, formatted_text)

            # 4. æ›´æ–°ç´€éŒ„
            with open(LAST_NEWS_FILE, "w", encoding="utf-8") as f:
                f.write(title)

        except Exception as e:
            print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
        finally:
            browser.close()

if __name__ == "__main__":
    run_scraper()
